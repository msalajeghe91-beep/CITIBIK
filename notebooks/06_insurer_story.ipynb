{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# CitiBike Insurance Partnership Analysis\n",
    "\n",
    "**Purpose**: Usage patterns and business decision assets for AXA partnership\n",
    "\n",
    "**Run via**: `make run-notebooks MODE=nyc` or `make all-both`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP\n",
    "# ============================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Configuration from Makefile\n",
    "RUN_DIR = os.environ.get(\"CITIBIKE_RUN_DIR\")\n",
    "mode = os.environ.get(\"CITIBIKE_MODE\", \"unknown\")\n",
    "\n",
    "if not RUN_DIR:\n",
    "    raise ValueError(\n",
    "        \"CITIBIKE_RUN_DIR not set.\\n\"\n",
    "        \"Run via Makefile: make run-notebooks MODE=nyc\"\n",
    "    )\n",
    "\n",
    "RUN_DIR = Path(RUN_DIR)\n",
    "run_label = RUN_DIR.name\n",
    "\n",
    "print(f\"Mode: {mode}\")\n",
    "print(f\"Run directory: {RUN_DIR}\")\n",
    "print(f\"Run label: {run_label}\")\n",
    "\n",
    "# Load CSVs\n",
    "df_year = pd.read_csv(RUN_DIR / \"citibike_trips_by_year.csv\")\n",
    "df_month = pd.read_csv(RUN_DIR / \"citibike_trips_by_month.csv\")\n",
    "df_dow = pd.read_csv(RUN_DIR / \"citibike_trips_by_dow.csv\")\n",
    "df_hour = pd.read_csv(RUN_DIR / \"citibike_trips_by_hour.csv\")\n",
    "\n",
    "# Scorecard (try 500m first)\n",
    "scorecard_path = RUN_DIR / \"axa_partner_scorecard_500m.csv\"\n",
    "if not scorecard_path.exists():\n",
    "    for p in RUN_DIR.glob(\"axa_partner_scorecard_*m.csv\"):\n",
    "        scorecard_path = p\n",
    "        break\n",
    "df_score = pd.read_csv(scorecard_path) if scorecard_path.exists() else None\n",
    "\n",
    "# Windows\n",
    "windows_path = RUN_DIR / \"axa_target_windows.csv\"\n",
    "df_windows = pd.read_csv(windows_path) if windows_path.exists() else None\n",
    "\n",
    "# Highlights path\n",
    "highlights_path = RUN_DIR / \"summary_highlights.md\"\n",
    "\n",
    "print(f\"\\nLoaded:\")\n",
    "print(f\"  df_year:    {len(df_year)} rows\")\n",
    "print(f\"  df_month:   {len(df_month)} rows\")\n",
    "print(f\"  df_dow:     {len(df_dow)} rows\")\n",
    "print(f\"  df_hour:    {len(df_hour)} rows\")\n",
    "print(f\"  df_score:   {len(df_score) if df_score is not None else 'None'} rows\")\n",
    "print(f\"  df_windows: {len(df_windows) if df_windows is not None else 'None'} rows\")\n",
    "\n",
    "# Figure output\n",
    "FIG_DIR = RUN_DIR.parent.parent / \"reports\" / run_label / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def savefig(name):\n",
    "    path = FIG_DIR / name\n",
    "    plt.savefig(path, dpi=150, bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "highlights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick text highlights from summarize script (if present) ---\n",
    "if highlights_path.exists():\n",
    "    txt = highlights_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    display(Markdown(txt))\n",
    "else:\n",
    "    print(\"No summary_highlights.md found at:\", highlights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trips-by-year",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Trips by year (THIS RUN) ---\n",
    "g = df_year.copy()\n",
    "g[\"year\"] = pd.to_numeric(g[\"year\"], errors=\"coerce\")\n",
    "g = g.dropna(subset=[\"year\"]).sort_values(\"year\").reset_index(drop=True)\n",
    "\n",
    "display(g)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "years = [int(y) for y in g[\"year\"]]\n",
    "trips = [int(t) for t in g[\"trips\"]]\n",
    "\n",
    "plt.plot(years, trips, marker=\"o\", linewidth=2, markersize=8, color='#2E86AB')\n",
    "plt.xticks(years, [str(y) for y in years])\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "for year, trip in zip(years, trips):\n",
    "    plt.text(year, trip, f'{trip/1e6:.2f}M', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.title(f\"Trips by year — mode={mode} ({run_label})\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Year\", fontsize=12)\n",
    "plt.ylabel(\"Trips\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "savefig(\"01_trips_by_year.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trips-by-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Trips by month (THIS RUN) ---\n",
    "m = df_month.copy()\n",
    "m[\"month\"] = pd.to_numeric(m[\"month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "m[\"year\"] = pd.to_numeric(m[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "display(m.sort_values([\"year\", \"month\"]))\n",
    "\n",
    "# Plot\n",
    "m2 = m.dropna(subset=[\"year\", \"month\"]).copy()\n",
    "m2[\"ym\"] = m2[\"year\"].astype(int).astype(str) + \"-\" + m2[\"month\"].astype(int).astype(str).str.zfill(2)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(m2[\"ym\"], m2[\"trips\"])\n",
    "plt.title(f\"Trips by year-month — mode={mode} ({run_label})\")\n",
    "plt.xlabel(\"Year-Month\")\n",
    "plt.ylabel(\"Trips\")\n",
    "plt.xticks(rotation=75, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "savefig(\"02_trips_by_year_month.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Month-of-year seasonality (one line per year) ---\n",
    "m = df_month.copy()\n",
    "m[\"month\"] = pd.to_numeric(m[\"month\"], errors=\"coerce\")\n",
    "m[\"year\"] = pd.to_numeric(m[\"year\"], errors=\"coerce\")\n",
    "m = m.dropna(subset=[\"year\", \"month\"])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for yr in sorted(m[\"year\"].unique()):\n",
    "    sub = m[m[\"year\"] == yr].sort_values(\"month\")\n",
    "    plt.plot(sub[\"month\"], sub[\"trips\"], marker=\"o\", label=str(int(yr)))\n",
    "\n",
    "plt.title(f\"Month-of-year seasonality — mode={mode} ({run_label})\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Month\", fontsize=12)\n",
    "plt.ylabel(\"Trips\", fontsize=12)\n",
    "plt.xticks(range(1, 13))\n",
    "plt.legend(title=\"Year\")\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "savefig(\"03_month_of_year_seasonality.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Day-of-week patterns ---\n",
    "d = df_dow.copy()\n",
    "d[\"dow\"] = pd.to_numeric(d[\"dow\"], errors=\"coerce\")\n",
    "d[\"trips\"] = pd.to_numeric(d[\"trips\"], errors=\"coerce\").fillna(0)\n",
    "d[\"year\"] = pd.to_numeric(d[\"year\"], errors=\"coerce\")\n",
    "d = d.dropna(subset=[\"dow\", \"year\"]).copy()\n",
    "d[\"dow\"] = d[\"dow\"].astype(int)\n",
    "d[\"year\"] = d[\"year\"].astype(int)\n",
    "\n",
    "dow_map = {0: \"Monday\", 1: \"Tuesday\", 2: \"Wednesday\", 3: \"Thursday\",\n",
    "           4: \"Friday\", 5: \"Saturday\", 6: \"Sunday\"}\n",
    "d[\"dow_name\"] = d[\"dow\"].map(dow_map)\n",
    "\n",
    "display(d.sort_values([\"year\", \"dow\"]))\n",
    "\n",
    "# Pivot for plotting\n",
    "pivot = d.pivot_table(index=[\"dow\", \"dow_name\"], columns=\"year\", values=\"trips\", aggfunc=\"sum\").sort_index(level=0)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "x_labels = [n for n in pivot.index.get_level_values(\"dow_name\")]\n",
    "x = np.arange(len(x_labels))\n",
    "\n",
    "for yr in pivot.columns:\n",
    "    plt.plot(x, pivot[yr].values, marker=\"o\", label=str(yr))\n",
    "\n",
    "plt.xticks(x, x_labels, rotation=30, ha=\"right\")\n",
    "plt.title(f\"Day-of-week pattern — mode={mode} ({run_label})\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Day of Week\", fontsize=12)\n",
    "plt.ylabel(\"Trips\", fontsize=12)\n",
    "plt.legend(title=\"Year\")\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "savefig(\"04_dow_pattern.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dow-shares",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Day-of-week % shares per year ---\n",
    "shares = d.groupby([\"year\", \"dow\", \"dow_name\"], as_index=False)[\"trips\"].sum().sort_values([\"year\", \"dow\"])\n",
    "shares[\"pct_of_year\"] = shares[\"trips\"] / shares.groupby(\"year\")[\"trips\"].transform(\"sum\") * 100.0\n",
    "\n",
    "display(shares)\n",
    "\n",
    "pivot_pct = shares.pivot(index=\"dow_name\", columns=\"year\", values=\"pct_of_year\")\n",
    "pivot_pct = pivot_pct.reindex([dow_map[i] for i in range(7)])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "x = np.arange(len(pivot_pct.index))\n",
    "\n",
    "for yr in pivot_pct.columns:\n",
    "    plt.plot(x, pivot_pct[yr].values, marker=\"o\", label=str(yr))\n",
    "\n",
    "plt.xticks(x, pivot_pct.index, rotation=30, ha=\"right\")\n",
    "plt.title(f\"Day-of-week % share — mode={mode} ({run_label})\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Day of Week\", fontsize=12)\n",
    "plt.ylabel(\"% of Year's Trips\", fontsize=12)\n",
    "plt.legend(title=\"Year\")\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "savefig(\"05_dow_pct_share.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hour",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hour-of-day patterns ---\n",
    "h = df_hour.copy()\n",
    "h[\"hour\"] = pd.to_numeric(h[\"hour\"], errors=\"coerce\")\n",
    "h[\"trips\"] = pd.to_numeric(h[\"trips\"], errors=\"coerce\").fillna(0)\n",
    "h[\"year\"] = pd.to_numeric(h[\"year\"], errors=\"coerce\")\n",
    "h = h.dropna(subset=[\"hour\", \"year\"]).copy()\n",
    "\n",
    "display(h.sort_values([\"year\", \"hour\"]).head(20))\n",
    "\n",
    "# Check for week_part column\n",
    "part_col = \"week_part\" if \"week_part\" in h.columns else None\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "if part_col:\n",
    "    for (yr, seg), sub in h.groupby([\"year\", part_col]):\n",
    "        sub = sub.sort_values(\"hour\")\n",
    "        plt.plot(sub[\"hour\"], sub[\"trips\"], marker=\"o\", label=f\"{int(yr)} | {seg}\")\n",
    "else:\n",
    "    for yr, sub in h.groupby(\"year\"):\n",
    "        sub = sub.sort_values(\"hour\")\n",
    "        plt.plot(sub[\"hour\"], sub[\"trips\"], marker=\"o\", label=str(int(yr)))\n",
    "\n",
    "plt.title(f\"Hour-of-day pattern — mode={mode} ({run_label})\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Hour\", fontsize=12)\n",
    "plt.ylabel(\"Trips\", fontsize=12)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.legend(title=\"Year / Segment\", fontsize=8, ncol=2)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "\n",
    "savefig(\"06_hour_of_day.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Crash proximity risk proxy (NYC only): YEARLY comparison ---\n",
    "MIN_TRIPS_FOR_CREDIBLE_DISPLAY = 5000\n",
    "TOP_N = 20\n",
    "\n",
    "if df_score is None or df_score.empty:\n",
    "    print(\"Skipping yearly risk analysis - no scorecard data available\")\n",
    "elif \"year\" not in df_score.columns:\n",
    "    print(\"Scorecard has no 'year' column (overall aggregate only).\")\n",
    "else:\n",
    "    r = df_score.copy()\n",
    "    \n",
    "    # Normalize column names\n",
    "    r = r.rename(columns={\n",
    "        \"start_station_id\": \"station_id\",\n",
    "        \"start_station_name\": \"station_name\"\n",
    "    }, errors=\"ignore\")\n",
    "    \n",
    "    # Get trips column\n",
    "    r[\"trips\"] = pd.to_numeric(r.get(\"exposure_trips\", r.get(\"trips\", 0)), errors=\"coerce\")\n",
    "    r = r[r[\"trips\"] >= MIN_TRIPS_FOR_CREDIBLE_DISPLAY].copy()\n",
    "    \n",
    "    years = sorted(r[\"year\"].dropna().unique())\n",
    "    \n",
    "    print(f\"\\n=== Yearly Risk Analysis (using scorecard EB estimates) ===\")\n",
    "    print(f\"Stations with ≥{MIN_TRIPS_FOR_CREDIBLE_DISPLAY:,} trips\")\n",
    "    \n",
    "    yearly_burden = []\n",
    "    \n",
    "    for yy in years:\n",
    "        ry = r[r[\"year\"] == yy].copy()\n",
    "        if ry.empty:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n--- Year {int(yy)} ---\")\n",
    "        \n",
    "        print(f\"Top {TOP_N} by exposure:\")\n",
    "        display(ry.sort_values(\"trips\", ascending=False).head(TOP_N)[\n",
    "            [\"mode\", \"year\", \"station_id\", \"station_name\", \"trips\"]\n",
    "        ])\n",
    "        \n",
    "        print(f\"Top {TOP_N} by EB risk rate:\")\n",
    "        display(ry.sort_values(\"eb_risk_rate_per_100k_trips\", ascending=False).head(TOP_N)[\n",
    "            [\"mode\", \"year\", \"station_id\", \"station_name\", \"trips\", \n",
    "             \"crash_count\", \"eb_risk_rate_per_100k_trips\"]\n",
    "        ])\n",
    "        \n",
    "        if \"expected_incidents_proxy\" in ry.columns:\n",
    "            yearly_burden.append({\"year\": int(yy), \"eb_expected_crashes\": ry[\"expected_incidents_proxy\"].sum()})\n",
    "    \n",
    "    # Plot yearly burden\n",
    "    if yearly_burden:\n",
    "        yb = pd.DataFrame(yearly_burden).sort_values(\"year\")\n",
    "        \n",
    "        plt.figure(figsize=(9, 4))\n",
    "        plt.bar(yb[\"year\"].astype(str), yb[\"eb_expected_crashes\"].values)\n",
    "        plt.title(f\"Yearly EB crash-proxy burden — mode={mode}\")\n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Expected incidents (sum across stations)\")\n",
    "        plt.tight_layout()\n",
    "        savefig(\"09_yearly_EB_crash_proxy_burden.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nTotal EB expected crashes by year:\")\n",
    "        display(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exposure vs Risk \"Zones\" (EB-smoothed quadrant view) ---\n",
    "MIN_TRIPS_FOR_ZONES = 5000\n",
    "\n",
    "if df_score is None or df_score.empty:\n",
    "    print(\"No scorecard data — skipping zones plot\")\n",
    "else:\n",
    "    r = df_score.copy()\n",
    "    \n",
    "    # Normalize column names\n",
    "    r = r.rename(columns={\n",
    "        \"start_station_id\": \"station_id\",\n",
    "        \"start_station_name\": \"station_name\",\n",
    "        \"exposure_trips\": \"trips\"\n",
    "    }, errors=\"ignore\")\n",
    "    \n",
    "    # Get risk metric\n",
    "    if \"eb_risk_rate_per_100k_trips\" in r.columns:\n",
    "        r[\"risk_rate\"] = pd.to_numeric(r[\"eb_risk_rate_per_100k_trips\"], errors=\"coerce\")\n",
    "        risk_metric_name = \"EB-smoothed risk rate per 100k trips\"\n",
    "    elif \"risk_rate_per_100k_trips\" in r.columns:\n",
    "        r[\"risk_rate\"] = pd.to_numeric(r[\"risk_rate_per_100k_trips\"], errors=\"coerce\")\n",
    "        risk_metric_name = \"Raw risk rate per 100k trips\"\n",
    "    else:\n",
    "        print(\"No risk rate column found\")\n",
    "        r = None\n",
    "    \n",
    "    if r is not None:\n",
    "        r[\"trips\"] = pd.to_numeric(r[\"trips\"], errors=\"coerce\")\n",
    "        r = r.dropna(subset=[\"trips\", \"risk_rate\"])\n",
    "        r = r[r[\"trips\"] >= MIN_TRIPS_FOR_ZONES].copy()\n",
    "        \n",
    "        if len(r) == 0:\n",
    "            print(f\"No stations meet trips ≥ {MIN_TRIPS_FOR_ZONES} — skipping zones plot.\")\n",
    "        else:\n",
    "            print(f\"Plotting {len(r):,} stations with ≥ {MIN_TRIPS_FOR_ZONES:,} trips\")\n",
    "            \n",
    "            x_med = r[\"trips\"].median()\n",
    "            y_med = r[\"risk_rate\"].median()\n",
    "            \n",
    "            print(f\"Median exposure: {x_med:,.0f} trips\")\n",
    "            print(f\"Median risk: {y_med:.2f}\")\n",
    "            \n",
    "            # Classify into zones\n",
    "            def zone(row):\n",
    "                hi_x = row[\"trips\"] >= x_med\n",
    "                hi_y = row[\"risk_rate\"] >= y_med\n",
    "                if hi_x and hi_y: return \"High exposure / High risk\"\n",
    "                if hi_x: return \"High exposure / Lower risk\"\n",
    "                if hi_y: return \"Lower exposure / High risk\"\n",
    "                return \"Lower exposure / Lower risk\"\n",
    "            \n",
    "            r[\"zone\"] = r.apply(zone, axis=1)\n",
    "            \n",
    "            print(\"\\nZone distribution:\")\n",
    "            display(r[\"zone\"].value_counts().to_frame(\"stations\"))\n",
    "            \n",
    "            # Plot\n",
    "            zone_colors = {\n",
    "                \"High exposure / High risk\": \"#d62728\",\n",
    "                \"High exposure / Lower risk\": \"#2ca02c\",\n",
    "                \"Lower exposure / High risk\": \"#ff7f0e\",\n",
    "                \"Lower exposure / Lower risk\": \"#1f77b4\"\n",
    "            }\n",
    "            \n",
    "            plt.figure(figsize=(10, 7))\n",
    "            \n",
    "            for z, sub in r.groupby(\"zone\"):\n",
    "                plt.scatter(sub[\"trips\"], sub[\"risk_rate\"], alpha=0.6, s=60,\n",
    "                           label=f\"{z} (n={len(sub)})\", color=zone_colors.get(z, \"#999999\"))\n",
    "            \n",
    "            plt.axvline(x_med, linestyle=\"--\", color=\"gray\", alpha=0.7, linewidth=1.5,\n",
    "                       label=f\"Median exposure ({x_med:,.0f})\")\n",
    "            plt.axhline(y_med, linestyle=\"--\", color=\"gray\", alpha=0.7, linewidth=1.5,\n",
    "                       label=f\"Median risk ({y_med:.2f})\")\n",
    "            \n",
    "            plt.xscale(\"log\")\n",
    "            plt.xlabel(\"Exposure (trips, log scale)\", fontsize=11)\n",
    "            plt.ylabel(risk_metric_name, fontsize=11)\n",
    "            plt.title(f\"Exposure vs Risk Zones — EB-smoothed\\n(stations with ≥ {MIN_TRIPS_FOR_ZONES:,} trips, mode={mode})\",\n",
    "                     fontsize=12, fontweight=\"bold\")\n",
    "            plt.legend(fontsize=8, loc=\"best\")\n",
    "            plt.grid(True, alpha=0.3, linestyle=\":\")\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            savefig(f\"10_zones_exposure_vs_risk.png\")\n",
    "            plt.show()\n",
    "            \n",
    "            # High priority table\n",
    "            hh = r[r[\"zone\"] == \"High exposure / High risk\"].sort_values(\"risk_rate\", ascending=False).head(15)\n",
    "            \n",
    "            print(f\"\\n HIGH PRIORITY STATIONS (High exposure + High risk, top 15):\")\n",
    "            display_cols = [c for c in [\"mode\", \"station_id\", \"station_name\", \"trips\", \"risk_rate\", \n",
    "                                        \"crash_count\", \"credibility_flag\"] if c in hh.columns]\n",
    "            display(hh[display_cols])\n",
    "            \n",
    "            # Business interpretation\n",
    "            print(f\"\\n Business Interpretation:\")\n",
    "            print(f\"  • {len(hh)} high-priority stations → Prevention pilots & safety interventions\")\n",
    "            high_exp_low_risk = len(r[r[\"zone\"] == \"High exposure / Lower risk\"])\n",
    "            print(f\"  • {high_exp_low_risk} high-exposure/low-risk stations → Product upsell targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "axa-decision-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AXA Decision Assets (INSURER-READY): WHERE + WHEN + WHAT ---\n",
    "MIN_TRIPS = 5000\n",
    "TOP_N = 20\n",
    "\n",
    "def drop_bool_cols(df):\n",
    "    \"\"\"Remove True/False columns for presentation.\"\"\"\n",
    "    bool_cols = [c for c in df.columns if df[c].dtype == bool]\n",
    "    for c in df.columns:\n",
    "        if c not in bool_cols and df[c].dtype == object:\n",
    "            unique_vals = set(df[c].dropna().unique())\n",
    "            if unique_vals.issubset({True, False, 'True', 'False'}):\n",
    "                bool_cols.append(c)\n",
    "    return df.drop(columns=bool_cols, errors=\"ignore\")\n",
    "\n",
    "if df_score is None or df_windows is None:\n",
    "    print(\"Missing inputs:\")\n",
    "    print(f\"  df_score:   {'OK' if df_score is not None else 'MISSING'}\")\n",
    "    print(f\"  df_windows: {'OK' if df_windows is not None else 'MISSING'}\")\n",
    "else:\n",
    "    score = df_score.copy()\n",
    "    win = df_windows.copy()\n",
    "    \n",
    "    # Defensive typing\n",
    "    for c in [\"exposure_trips\", \"crash_count\", \"risk_rate_per_100k_trips\",\n",
    "              \"eb_risk_rate_per_100k_trips\", \"expected_incidents_proxy\", \"axa_priority_score\"]:\n",
    "        if c in score.columns:\n",
    "            score[c] = pd.to_numeric(score[c], errors=\"coerce\")\n",
    "    \n",
    "    # Ensure credibility flag\n",
    "    if \"credibility_flag\" not in score.columns:\n",
    "        score[\"credibility_flag\"] = np.where(\n",
    "            score.get(\"exposure_trips\", 0) >= MIN_TRIPS, \"credible\", \"insufficient_data\"\n",
    "        )\n",
    "    \n",
    "    # Column names\n",
    "    id_col = \"start_station_id\" if \"start_station_id\" in score.columns else \"station_id\"\n",
    "    name_col = \"start_station_name\" if \"start_station_name\" in score.columns else \"station_name\"\n",
    "    \n",
    "    # === WHERE (Prevention) ===\n",
    "    prevention = score[score[\"credibility_flag\"] == \"credible\"].copy()\n",
    "    \n",
    "    if \"expected_incidents_proxy\" in prevention.columns:\n",
    "        prevention = prevention.sort_values([\"expected_incidents_proxy\", \"exposure_trips\"], ascending=False)\n",
    "        rank_label = \"expected burden (risk × exposure)\"\n",
    "    else:\n",
    "        prevention = prevention.sort_values([\"axa_priority_score\", \"exposure_trips\"], ascending=False)\n",
    "        rank_label = \"axa_priority_score\"\n",
    "    \n",
    "    where_cols = [c for c in [\n",
    "        \"mode\", \"year\", \"month\", id_col, name_col,\n",
    "        \"exposure_trips\", \"crash_count\", \"eb_risk_rate_per_100k_trips\",\n",
    "        \"expected_incidents_proxy\", \"axa_priority_score\", \"credibility_flag\"\n",
    "    ] if c and c in prevention.columns]\n",
    "    \n",
    "    prevention_show = drop_bool_cols(prevention[where_cols])\n",
    "    \n",
    "    print(f\"\\nWHERE (Prevention) — Top {TOP_N} credible station-periods by {rank_label}\")\n",
    "    print(f\"Credibility rule: exposure_trips ≥ {MIN_TRIPS:,}\\n\")\n",
    "    display(prevention_show.head(TOP_N))\n",
    "    \n",
    "    print(f\"\\nPrevention pool size: {len(prevention):,} rows (credible)\")\n",
    "    if \"expected_incidents_proxy\" in prevention.columns:\n",
    "        print(f\"Total expected burden (sum expected_incidents_proxy): {prevention['expected_incidents_proxy'].sum():,.1f}\")\n",
    "    \n",
    "    # === WHERE (Reach) ===\n",
    "    reach = score.sort_values(\"exposure_trips\", ascending=False).copy()\n",
    "    \n",
    "    reach_cols = [c for c in [\n",
    "        \"mode\", \"year\", \"month\", id_col, name_col, \"exposure_trips\", \"credibility_flag\"\n",
    "    ] if c and c in reach.columns]\n",
    "    \n",
    "    reach_show = drop_bool_cols(reach[reach_cols])\n",
    "    \n",
    "    print(f\"\\nWHERE (Reach) — Top {TOP_N} station-periods by exposure_trips\")\n",
    "    display(reach_show.head(TOP_N))\n",
    "    \n",
    "    # === WHEN ===\n",
    "    for c in [\"trips\", \"pct_of_mode_year_trips\", \"pct_within_week_part\", \"priority_metric\"]:\n",
    "        if c in win.columns:\n",
    "            win[c] = pd.to_numeric(win[c], errors=\"coerce\")\n",
    "    \n",
    "    w_rank = \"priority_metric\" if \"priority_metric\" in win.columns else \"trips\"\n",
    "    when = win.sort_values(w_rank, ascending=False).head(TOP_N) if w_rank else win.head(TOP_N)\n",
    "    \n",
    "    when_cols = [c for c in [\n",
    "        \"window_type\", \"segment\", \"window_label\",\n",
    "        \"trips\", \"pct_of_mode_year_trips\", \"priority_metric\", \"recommended_action\"\n",
    "    ] if c in when.columns]\n",
    "    \n",
    "    when_show = drop_bool_cols(when[when_cols])\n",
    "    \n",
    "    print(f\"\\nWHEN — Top {TOP_N} activation windows by {w_rank}\")\n",
    "    display(when_show)\n",
    "    \n",
    "    # === WHAT ===\n",
    "    print(\"\\nWHAT (insurer-ready plan):\")\n",
    "    print(f\"- Prevention: prioritize credible stations (≥{MIN_TRIPS:,} trips) ranked by expected burden (risk × exposure).\")\n",
    "    print(f\"- Timing: activate in the highest-traffic windows (ranked by {w_rank}) to maximize reach and conversion.\")\n",
    "    print(f\"- Measurement: short-term conversion lift; mid-term change in incident proxy at treated stations; long-term claims frequency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary ---\n",
    "print(\"=\"*60)\n",
    "print(f\"SUMMARY — mode={mode} ({run_label})\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total trips: {df_year['trips'].sum():,.0f}\")\n",
    "\n",
    "if df_score is not None:\n",
    "    id_col = \"start_station_id\" if \"start_station_id\" in df_score.columns else \"station_id\"\n",
    "    print(f\"Unique stations: {df_score[id_col].nunique():,}\")\n",
    "    print(f\"Station-periods: {len(df_score):,}\")\n",
    "    \n",
    "    if \"credibility_flag\" in df_score.columns:\n",
    "        print(f\"Credible station-periods: {(df_score['credibility_flag'] == 'credible').sum():,}\")\n",
    "    \n",
    "    if \"prevention_hotspot\" in df_score.columns:\n",
    "        print(f\"Prevention hotspots: {df_score['prevention_hotspot'].sum():,}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
