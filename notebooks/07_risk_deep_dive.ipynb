{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8edcd816",
   "metadata": {},
   "source": [
    "# Risk Deep Dive: Detailed risk analysis\n",
    "\n",
    "This notebook is built to work with the repo Make targets (e.g.make report-both YEARS=\"YYYY YYYY...\" MONTHS=\"1 2 .. 12\")\n",
    "It **always prefers the current run** (your `summaries/<RUN_TAG>/` folder) when you pass `YEARS/MONTHS`, so the report reflects exactly what you ingested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1edc51",
   "metadata": {},
   "source": [
    "## How to run (recommended)\n",
    "\n",
    "From the repo root:\n",
    "```bash\n",
    "make all-both YEARS=\"YYYY YYYY...\" MONTHS=\"1 2 .. 12\"\n",
    "\n",
    "The Makefile sets environment variables (e.g. `CITIBIKE_PARQUET_DIR`, `CITIBIKE_YEARS`, `CITIBIKE_MONTHS`) which this notebook reads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f74bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, Markdown\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# --- Setup (STRICT): load summaries + FORCE year/month risk tables (NO overall fallback) ---\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Notebook-friendly display\n",
    "try:\n",
    "    from IPython.display import display, Markdown\n",
    "except Exception:\n",
    "    display = print\n",
    "    Markdown = lambda x: x\n",
    "\n",
    "# Ensure figures render in executed notebook\n",
    "try:\n",
    "    get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "plt.ioff()  # nbconvert-friendly\n",
    "\n",
    "# ---------------------------\n",
    "# Repo discovery\n",
    "# ---------------------------\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"Makefile\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"Could not find repo root (Makefile) from CWD={Path.cwd().resolve()}\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "SUMMARIES_ROOT = REPO_ROOT / \"summaries\"\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def _parse_int_list(val: str | None):\n",
    "    if val is None:\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    parts = re.split(r\"[,\\s]+\", s)\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        if not p:\n",
    "            continue\n",
    "        try:\n",
    "            out.append(int(p))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out or None\n",
    "\n",
    "def read_csv_strict(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing required CSV: {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def read_csv_optional(path: Path) -> pd.DataFrame | None:\n",
    "    return pd.read_csv(path) if path.exists() else None\n",
    "\n",
    "def _filter_year_month(df: pd.DataFrame, years: list[int] | None, months: list[int] | None) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    if years is not None and \"year\" in out.columns:\n",
    "        out[\"year\"] = pd.to_numeric(out[\"year\"], errors=\"coerce\")\n",
    "        out = out[out[\"year\"].isin(years)]\n",
    "    if months is not None and \"month\" in out.columns:\n",
    "        out[\"month\"] = pd.to_numeric(out[\"month\"], errors=\"coerce\")\n",
    "        out = out[out[\"month\"].isin(months)]\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# Inputs from Makefile\n",
    "# ---------------------------\n",
    "PARQUET_DIR_ENV = (os.environ.get(\"CITIBIKE_PARQUET_DIR\") or \"\").strip()\n",
    "RUN_DIR_ENV     = (os.environ.get(\"CITIBIKE_RUN_DIR\") or \"\").strip()\n",
    "MODE_ENV        = (os.environ.get(\"CITIBIKE_MODE\") or os.environ.get(\"MODE\") or \"\").strip().lower()\n",
    "\n",
    "YEARS_FILTER  = _parse_int_list(os.environ.get(\"CITIBIKE_YEARS\")  or os.environ.get(\"YEARS\"))\n",
    "MONTHS_FILTER = _parse_int_list(os.environ.get(\"CITIBIKE_MONTHS\") or os.environ.get(\"MONTHS\"))\n",
    "\n",
    "PARQUET_DIR = Path(PARQUET_DIR_ENV) if PARQUET_DIR_ENV else Path()\n",
    "\n",
    "if RUN_DIR_ENV:\n",
    "    RUN_DIR = Path(RUN_DIR_ENV)\n",
    "else:\n",
    "    run_tag = PARQUET_DIR.name if str(PARQUET_DIR).strip() else \"\"\n",
    "    RUN_DIR = (SUMMARIES_ROOT / run_tag) if run_tag else Path()\n",
    "\n",
    "# Resolve relative -> absolute\n",
    "if str(RUN_DIR).strip() and not RUN_DIR.is_absolute():\n",
    "    RUN_DIR = (REPO_ROOT / RUN_DIR).resolve()\n",
    "if str(PARQUET_DIR).strip() and not PARQUET_DIR.is_absolute():\n",
    "    PARQUET_DIR = (REPO_ROOT / PARQUET_DIR).resolve()\n",
    "\n",
    "# ---------------------------\n",
    "# Strict checks\n",
    "# ---------------------------\n",
    "if not SUMMARIES_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Expected summaries/ folder at: {SUMMARIES_ROOT}\")\n",
    "if not RUN_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Expected run summaries at: {RUN_DIR}\")\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"RUN_DIR:\", RUN_DIR)\n",
    "print(\"PARQUET_DIR:\", PARQUET_DIR if str(PARQUET_DIR).strip() else \"(not set)\")\n",
    "print(\"MODE (env):\", MODE_ENV or \"(not set)\")\n",
    "print(\"YEARS_FILTER:\", YEARS_FILTER, \"MONTHS_FILTER:\", MONTHS_FILTER)\n",
    "\n",
    "# Figures dir\n",
    "FIG_DIR = REPO_ROOT / \"reports\" / RUN_DIR.name / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"FIG_DIR:\", FIG_DIR)\n",
    "\n",
    "def savefig(filename: str):\n",
    "    out = FIG_DIR / filename\n",
    "    plt.savefig(out, dpi=200, bbox_inches=\"tight\")\n",
    "    print(\"Saved:\", out)\n",
    "\n",
    "# ---------------------------\n",
    "# Load core per-run summaries (required)\n",
    "# ---------------------------\n",
    "df_year  = read_csv_strict(RUN_DIR / \"citibike_trips_by_year.csv\")\n",
    "df_month = read_csv_strict(RUN_DIR / \"citibike_trips_by_month.csv\")\n",
    "df_dow   = read_csv_strict(RUN_DIR / \"citibike_trips_by_dow.csv\")\n",
    "df_hour  = read_csv_strict(RUN_DIR / \"citibike_trips_by_hour.csv\")\n",
    "\n",
    "# Optional outputs\n",
    "df_station = read_csv_optional(RUN_DIR / \"citibike_station_exposure.csv\")\n",
    "\n",
    "# ---------------------------\n",
    "# Load RISK (FORCE granular)\n",
    "# ---------------------------\n",
    "risk_year_path = RUN_DIR / \"station_risk_exposure_plus_crashproximity_by_year.csv\"\n",
    "risk_ym_path   = RUN_DIR / \"station_risk_exposure_plus_crashproximity_by_year_month.csv\"\n",
    "\n",
    "df_risk_year = read_csv_optional(risk_year_path)\n",
    "df_risk_ym   = read_csv_optional(risk_ym_path)\n",
    "\n",
    "# Force granular selection (no overall fallback)\n",
    "if df_risk_ym is not None:\n",
    "    df_risk = df_risk_ym\n",
    "    risk_source = \"by_year_month\"\n",
    "elif df_risk_year is not None:\n",
    "    df_risk = df_risk_year\n",
    "    risk_source = \"by_year\"\n",
    "else:\n",
    "    df_risk = None\n",
    "    risk_source = \"missing\"\n",
    "    raise FileNotFoundError(\n",
    "        \"No per-year/per-month risk CSVs found in RUN_DIR.\\n\"\n",
    "        f\"Expected one of:\\n  - {risk_ym_path}\\n  - {risk_year_path}\\n\"\n",
    "        \"If you truly want overall-only risk, load station_risk_exposure_plus_crashproximity.csv explicitly (but you said you don't).\"\n",
    "    )\n",
    "\n",
    "# Highlights\n",
    "highlights_path = RUN_DIR / \"summary_highlights.md\"\n",
    "\n",
    "# Mode detection\n",
    "mode = (\n",
    "    str(df_year[\"mode\"].iloc[0]).lower()\n",
    "    if (\"mode\" in df_year.columns and len(df_year))\n",
    "    else (MODE_ENV or \"unknown\")\n",
    ")\n",
    "print(\"Detected mode:\", mode)\n",
    "\n",
    "# Apply filters defensively\n",
    "df_year  = _filter_year_month(df_year,  YEARS_FILTER, MONTHS_FILTER)\n",
    "df_month = _filter_year_month(df_month, YEARS_FILTER, MONTHS_FILTER)\n",
    "df_dow   = _filter_year_month(df_dow,   YEARS_FILTER, MONTHS_FILTER)\n",
    "df_hour  = _filter_year_month(df_hour,  YEARS_FILTER, MONTHS_FILTER)\n",
    "\n",
    "df_risk  = _filter_year_month(df_risk,  YEARS_FILTER, MONTHS_FILTER)\n",
    "\n",
    "run_label = RUN_DIR.name\n",
    "\n",
    "print(\"\\nRisk files found:\")\n",
    "print(\" - by_year:\", \"YES\" if df_risk_year is not None else \"NO\")\n",
    "print(\" - by_year_month:\", \"YES\" if df_risk_ym is not None else \"NO\")\n",
    "print(\"Using df_risk =\", risk_source)\n",
    "print(\"df_risk columns:\", list(df_risk.columns))\n",
    "print(\"Unique years in df_risk:\", sorted(pd.to_numeric(df_risk[\"year\"], errors=\"coerce\").dropna().unique().astype(int).tolist()) if \"year\" in df_risk.columns else \"(no year)\")\n",
    "print(\"Unique months in df_risk:\", sorted(pd.to_numeric(df_risk[\"month\"], errors=\"coerce\").dropna().unique().astype(int).tolist()) if \"month\" in df_risk.columns else \"(no month)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327da89",
   "metadata": {},
   "source": [
    "### Risk Distribution Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HIGH-RISK STATIONS (nbconvert-safe, self-contained + year/month column on plot) ---\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MIN_TRIPS = 5000\n",
    "TOP_N = 10\n",
    "HIGH_RISK_PCT = 90  # top 10% by risk rate among credible rows\n",
    "\n",
    "_SCORE_RE = re.compile(r\"^axa_partner_scorecard_(\\d+)m\\.csv$\")\n",
    "\n",
    "def _available_scorecards(run_dir: Path) -> list[int]:\n",
    "    radii = []\n",
    "    for p in run_dir.glob(\"axa_partner_scorecard_*m.csv\"):\n",
    "        m = _SCORE_RE.match(p.name)\n",
    "        if m:\n",
    "            radii.append(int(m.group(1)))\n",
    "    return sorted(set(radii))\n",
    "\n",
    "def _pick_scorecard_path(run_dir: Path) -> Path | None:\n",
    "    radii = _available_scorecards(run_dir)\n",
    "    if not radii:\n",
    "        return None\n",
    "    # Stable default: prefer 500m if present; else max available\n",
    "    chosen = 500 if 500 in radii else max(radii)\n",
    "    p = run_dir / f\"axa_partner_scorecard_{chosen}m.csv\"\n",
    "    return p if p.exists() else None\n",
    "\n",
    "def _safe_read_csv(p: Path) -> pd.DataFrame | None:\n",
    "    try:\n",
    "        return pd.read_csv(p) if p and p.exists() else None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR reading {p}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -----------------------------\n",
    "# Ensure df_score exists (no NameError under nbconvert)\n",
    "# -----------------------------\n",
    "if \"RUN_DIR\" in globals() and RUN_DIR is not None:\n",
    "    run_dir = Path(RUN_DIR)\n",
    "else:\n",
    "    run_dir = Path(\".\").resolve()\n",
    "\n",
    "if \"df_score\" not in globals() or df_score is None or len(df_score) == 0:\n",
    "    score_path = _pick_scorecard_path(run_dir)\n",
    "    df_score = _safe_read_csv(score_path) if score_path else None\n",
    "\n",
    "if df_score is None or len(df_score) == 0:\n",
    "    print(\"  No scoring data found (df_score is missing/empty).\")\n",
    "    print(\"RUN_DIR used:\", run_dir)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HIGH-RISK STATIONS ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    s = df_score.copy()\n",
    "\n",
    "    # ---- Resolve column names robustly ----\n",
    "    id_col   = \"start_station_id\"   if \"start_station_id\"   in s.columns else (\"station_id\"   if \"station_id\"   in s.columns else None)\n",
    "    name_col = \"start_station_name\" if \"start_station_name\" in s.columns else (\"station_name\" if \"station_name\" in s.columns else None)\n",
    "    lat_col  = \"station_lat\" if \"station_lat\" in s.columns else (\"lat\" if \"lat\" in s.columns else None)\n",
    "    lng_col  = \"station_lng\" if \"station_lng\" in s.columns else (\"lng\" if \"lng\" in s.columns else None)\n",
    "\n",
    "    exposure_col = \"exposure_trips\" if \"exposure_trips\" in s.columns else (\"trips\" if \"trips\" in s.columns else None)\n",
    "    rate_col     = \"eb_risk_rate_per_100k_trips\" if \"eb_risk_rate_per_100k_trips\" in s.columns else (\n",
    "                   \"risk_rate_per_100k_trips\" if \"risk_rate_per_100k_trips\" in s.columns else None\n",
    "                 )\n",
    "    crash_col    = \"crash_count\" if \"crash_count\" in s.columns else None\n",
    "    cred_col     = \"credibility_flag\" if \"credibility_flag\" in s.columns else None\n",
    "\n",
    "    # Helpful context columns (optional)\n",
    "    has_year = \"year\" in s.columns\n",
    "    has_month = \"month\" in s.columns\n",
    "\n",
    "    missing_required = [k for k, v in {\n",
    "        \"station_id\": id_col,\n",
    "        \"station_name\": name_col,\n",
    "        \"exposure_trips\": exposure_col,\n",
    "        \"risk_rate\": rate_col,\n",
    "    }.items() if v is None]\n",
    "\n",
    "    if missing_required:\n",
    "        print(\"Cannot run high-risk analysis; missing columns:\", missing_required)\n",
    "        print(\"Available columns:\", list(s.columns))\n",
    "    else:\n",
    "        # ---- Clean numeric columns ----\n",
    "        s[exposure_col] = pd.to_numeric(s[exposure_col], errors=\"coerce\")\n",
    "        s[rate_col]     = pd.to_numeric(s[rate_col], errors=\"coerce\")\n",
    "        if crash_col is not None:\n",
    "            s[crash_col] = pd.to_numeric(s[crash_col], errors=\"coerce\")\n",
    "\n",
    "        if has_year:\n",
    "            s[\"year\"] = pd.to_numeric(s[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        if has_month:\n",
    "            s[\"month\"] = pd.to_numeric(s[\"month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "        # ---- Credible definition ----\n",
    "        if cred_col is not None:\n",
    "            credible = s[s[cred_col].astype(str).str.lower() == \"credible\"].copy()\n",
    "        else:\n",
    "            credible = s[s[exposure_col] >= MIN_TRIPS].copy()\n",
    "            print(f\"Note: no credibility_flag column; using exposure_trips ≥ {MIN_TRIPS:,} as credible.\")\n",
    "\n",
    "        credible = credible.dropna(subset=[exposure_col, rate_col]).copy()\n",
    "        credible = credible[credible[exposure_col] >= MIN_TRIPS].copy()\n",
    "\n",
    "        if len(credible) == 0:\n",
    "            print(\"No credible rows with usable risk data.\")\n",
    "        else:\n",
    "            # ---- Define high risk threshold on the credible distribution ----\n",
    "            cutoff = float(np.nanpercentile(credible[rate_col].values, HIGH_RISK_PCT))\n",
    "            high_risk = credible[credible[rate_col] >= cutoff].copy()\n",
    "\n",
    "            print(f\"High-risk threshold: {HIGH_RISK_PCT}th percentile of {rate_col} among credible rows\")\n",
    "            print(f\"Cutoff value: {cutoff:.2f}\")\n",
    "            print(f\"High-risk rows: {len(high_risk):,}\")\n",
    "            print(f\"Total exposure in high-risk rows: {high_risk[exposure_col].sum():,.0f} trips\")\n",
    "\n",
    "            # ---- Show Top N by risk rate ----\n",
    "            cols_to_show = [c for c in [\n",
    "                \"mode\",\n",
    "                \"year\" if has_year else None,\n",
    "                \"month\" if has_month else None,\n",
    "                id_col, name_col,\n",
    "                lat_col, lng_col,\n",
    "                exposure_col,\n",
    "                crash_col,\n",
    "                rate_col,\n",
    "            ] if c and c in high_risk.columns]\n",
    "\n",
    "            top_risk = (\n",
    "                high_risk.sort_values([rate_col, exposure_col], ascending=False)\n",
    "                         .head(TOP_N)[cols_to_show]\n",
    "                         .copy()\n",
    "            )\n",
    "\n",
    "            print(f\"\\nTop {TOP_N} Highest-Risk (credible) station-periods:\")\n",
    "            display(top_risk)\n",
    "\n",
    "            # ---- Print run scope so the plot is defensible ----\n",
    "            if has_year and has_month:\n",
    "                scope = (\n",
    "                    s.dropna(subset=[\"year\", \"month\"])\n",
    "                     .groupby([\"year\", \"month\"])\n",
    "                     .size()\n",
    "                     .reset_index(name=\"rows\")\n",
    "                     .sort_values([\"year\", \"month\"])\n",
    "                )\n",
    "                print(\"\\nScorecard scope (rows by year-month):\")\n",
    "                # nbconvert-safe print (display may not render)\n",
    "                print(scope.to_string(index=False))\n",
    "\n",
    "            # ---- Plot Top N with a Year/Month column on the right ----\n",
    "            try:\n",
    "                top_plot = top_risk.sort_values(rate_col, ascending=True).copy()\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                y = np.arange(len(top_plot))\n",
    "                vals = top_plot[rate_col].values\n",
    "\n",
    "                ax.barh(y, vals, edgecolor=\"black\")\n",
    "\n",
    "                # Left labels (station name)\n",
    "                ax.set_yticks(y)\n",
    "                ax.set_yticklabels([str(n)[:40] for n in top_plot[name_col]], fontsize=9)\n",
    "\n",
    "                ax.set_xlabel(\"Risk rate per 100k trips\", fontsize=11)\n",
    "                ax.set_title(f\"Top {TOP_N} Highest-Risk Station-Periods (Credible)\", fontsize=12, fontweight=\"bold\")\n",
    "                ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "                # Create space for right-side column\n",
    "                x_max = float(np.nanmax(vals)) if len(vals) else 0.0\n",
    "                pad = 0.18 * x_max if x_max > 0 else 1.0\n",
    "                ax.set_xlim(0, x_max + pad)\n",
    "\n",
    "                # Right column positions\n",
    "                x_sep = x_max + pad * 0.08\n",
    "                x_year = x_max + pad * 0.35\n",
    "                x_month = x_max + pad * 0.70\n",
    "\n",
    "                # Separator line\n",
    "                ax.axvline(x_sep, color=\"gray\", linewidth=1, alpha=0.6)\n",
    "\n",
    "                # Headers + values\n",
    "                if has_year and has_month:\n",
    "                    ax.text(x_year, len(y) - 0.15, \"Year\", ha=\"center\", va=\"bottom\",\n",
    "                            fontsize=10, fontweight=\"bold\")\n",
    "                    ax.text(x_month, len(y) - 0.15, \"Month\", ha=\"center\", va=\"bottom\",\n",
    "                            fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "                    for i, (_, row) in enumerate(top_plot.iterrows()):\n",
    "                        yr = row.get(\"year\", pd.NA)\n",
    "                        mo = row.get(\"month\", pd.NA)\n",
    "                        yr_txt = \"\" if pd.isna(yr) else str(int(yr))\n",
    "                        mo_txt = \"\" if pd.isna(mo) else str(int(mo)).zfill(2)\n",
    "                        ax.text(x_year, i, yr_txt, ha=\"center\", va=\"center\", fontsize=9)\n",
    "                        ax.text(x_month, i, mo_txt, ha=\"center\", va=\"center\", fontsize=9)\n",
    "\n",
    "                plt.tight_layout()\n",
    "                savefig(\"top10_highest_risk_station_periods.png\")\n",
    "                plt.show()\n",
    "                print(\"✓ Saved plot: top10_highest_risk_station_periods.png\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Could not generate plot: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: parse env selections\n",
    "# -----------------------------\n",
    "def _parse_int_list_env(name: str):\n",
    "    raw = os.environ.get(name, \"\").strip()\n",
    "    if not raw:\n",
    "        return None\n",
    "    parts = re.split(r\"[,\\s]+\", raw)\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "        try:\n",
    "            out.append(int(p))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return out or None\n",
    "\n",
    "MODE_ENV = (os.environ.get(\"CITIBIKE_MODE\", \"\") or \"unknown\").strip().lower()\n",
    "years_env = _parse_int_list_env(\"CITIBIKE_YEARS\")\n",
    "months_env = _parse_int_list_env(\"CITIBIKE_MONTHS\")\n",
    "\n",
    "# -----------------------------\n",
    "# Column choices\n",
    "# -----------------------------\n",
    "exposure_col = \"exposure_trips\"\n",
    "rate_col = \"eb_risk_rate_per_100k_trips\"\n",
    "crash_col = \"crash_count\" if \"crash_count\" in df_score.columns else None\n",
    "\n",
    "needed = [exposure_col, rate_col]\n",
    "missing = [c for c in needed if c not in df_score.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"df_score missing required columns: {missing}\")\n",
    "\n",
    "plot_df = df_score.copy()\n",
    "\n",
    "# Optional: only credible rows\n",
    "if \"credibility_flag\" in plot_df.columns:\n",
    "    plot_df = plot_df[plot_df[\"credibility_flag\"] == \"credible\"].copy()\n",
    "\n",
    "# Clean types\n",
    "plot_df[exposure_col] = pd.to_numeric(plot_df[exposure_col], errors=\"coerce\")\n",
    "plot_df[rate_col] = pd.to_numeric(plot_df[rate_col], errors=\"coerce\")\n",
    "if crash_col is not None:\n",
    "    plot_df[crash_col] = pd.to_numeric(plot_df[crash_col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "plot_df = plot_df.dropna(subset=[exposure_col, rate_col])\n",
    "plot_df = plot_df[plot_df[exposure_col] > 0].copy()\n",
    "\n",
    "has_period_cols = (\"year\" in plot_df.columns) and (\"month\" in plot_df.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# Styling helpers (matches your snippet)\n",
    "# -----------------------------\n",
    "def _draw_scatter(ax, df_slice: pd.DataFrame):\n",
    "    if crash_col is not None:\n",
    "        sc = ax.scatter(\n",
    "            df_slice[exposure_col],\n",
    "            df_slice[rate_col],\n",
    "            c=df_slice[crash_col].fillna(0),\n",
    "            alpha=0.6,\n",
    "            s=30,  # a bit smaller for dense multi-panels\n",
    "        )\n",
    "        return sc\n",
    "    else:\n",
    "        ax.scatter(\n",
    "            df_slice[exposure_col],\n",
    "            df_slice[rate_col],\n",
    "            alpha=0.6,\n",
    "            s=30,\n",
    "        )\n",
    "        return None\n",
    "\n",
    "def _mark_hotspots(ax, df_slice: pd.DataFrame):\n",
    "    if \"prevention_hotspot\" in df_slice.columns:\n",
    "        hotspots = df_slice[df_slice[\"prevention_hotspot\"] == True]\n",
    "        if len(hotspots) > 0:\n",
    "            ax.scatter(\n",
    "                hotspots[exposure_col],\n",
    "                hotspots[rate_col],\n",
    "                color=\"red\", s=130, marker=\"*\",\n",
    "                edgecolors=\"black\", linewidths=1,\n",
    "                label=\"Prevention Hotspots\", zorder=5\n",
    "            )\n",
    "            ax.legend(loc=\"best\", fontsize=7)\n",
    "\n",
    "def _style_axes(ax, title: str):\n",
    "    ax.set_xlabel(\"Exposure (trips)\", fontsize=9)\n",
    "    ax.set_ylabel(\"EB Risk Rate (per 100k trips)\", fontsize=9)\n",
    "    ax.set_title(title, fontsize=10, fontweight=\"bold\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# -----------------------------\n",
    "# If no year/month: do NOT crash (keeps all-both working)\n",
    "# -----------------------------\n",
    "if not has_period_cols:\n",
    "    print(f\"[panel] No year/month columns for MODE={MODE_ENV}. Making overall plot only.\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.2, 4.8))\n",
    "    sc = _draw_scatter(ax, plot_df)\n",
    "    _mark_hotspots(ax, plot_df)\n",
    "    _style_axes(ax, f\"Risk vs Exposure (overall) — mode={MODE_ENV}\")\n",
    "\n",
    "    if sc is not None:\n",
    "        plt.colorbar(sc, ax=ax, label=\"Crash Count\")\n",
    "\n",
    "    savefig(f\"risk_vs_exposure_overall_mode{MODE_ENV}.png\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # -----------------------------\n",
    "    # Prepare year/month selections (no hardcoding)\n",
    "    # -----------------------------\n",
    "    plot_df[\"year\"] = pd.to_numeric(plot_df[\"year\"], errors=\"coerce\")\n",
    "    plot_df[\"month\"] = pd.to_numeric(plot_df[\"month\"], errors=\"coerce\")\n",
    "    plot_df = plot_df.dropna(subset=[\"year\", \"month\"]).copy()\n",
    "    plot_df[\"year\"] = plot_df[\"year\"].astype(int)\n",
    "    plot_df[\"month\"] = plot_df[\"month\"].astype(int)\n",
    "\n",
    "    years_available = sorted(plot_df[\"year\"].unique())\n",
    "    months_available = sorted(plot_df[\"month\"].unique())\n",
    "\n",
    "    years_to_plot = years_env if years_env is not None else years_available\n",
    "    months_to_plot = months_env if months_env is not None else months_available\n",
    "\n",
    "    years_to_plot = [y for y in years_to_plot if y in years_available]\n",
    "    months_to_plot = [m for m in months_to_plot if m in months_available]\n",
    "\n",
    "    if not years_to_plot or not months_to_plot:\n",
    "        print(f\"[panel] No data after filtering for MODE={MODE_ENV}. years_env={years_env}, months_env={months_env}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"[panel] MODE={MODE_ENV} years={years_to_plot} months={months_to_plot} rows={len(plot_df):,}\")\n",
    "\n",
    "        # =========================================================\n",
    "        # PANEL A (paginated): one subplot per (year, month)\n",
    "        # =========================================================\n",
    "        pairs = [(y, m) for y in years_to_plot for m in months_to_plot]\n",
    "        total = len(pairs)\n",
    "\n",
    "        # Pagination settings (good for up to ~48+ plots)\n",
    "        PANELS_PER_PAGE = 12  # 12 => 3x4 (readable)\n",
    "        NCOLS = 3\n",
    "        NROWS = int(math.ceil(PANELS_PER_PAGE / NCOLS))\n",
    "        pages = int(math.ceil(total / PANELS_PER_PAGE))\n",
    "\n",
    "        print(f\"[panelA] Total period panels={total} -> pages={pages} (PANELS_PER_PAGE={PANELS_PER_PAGE})\")\n",
    "\n",
    "        # For a stable shared color scale across pages (so colors are comparable),\n",
    "        # compute global vmin/vmax once.\n",
    "        vmin = vmax = None\n",
    "        if crash_col is not None and len(plot_df) > 0:\n",
    "            vmin = float(plot_df[crash_col].min())\n",
    "            vmax = float(plot_df[crash_col].max())\n",
    "\n",
    "        for page_idx in range(pages):\n",
    "            start = page_idx * PANELS_PER_PAGE\n",
    "            end = min((page_idx + 1) * PANELS_PER_PAGE, total)\n",
    "            page_pairs = pairs[start:end]\n",
    "\n",
    "            figA, axesA = plt.subplots(\n",
    "                NROWS, NCOLS,\n",
    "                figsize=(4.6 * NCOLS, 3.6 * NROWS),\n",
    "                squeeze=False\n",
    "            )\n",
    "\n",
    "            scatter_for_cbar = None\n",
    "\n",
    "            for i, (y, m) in enumerate(page_pairs):\n",
    "                r, c = divmod(i, NCOLS)\n",
    "                ax = axesA[r][c]\n",
    "\n",
    "                d = plot_df[(plot_df[\"year\"] == y) & (plot_df[\"month\"] == m)].copy()\n",
    "\n",
    "                if crash_col is not None:\n",
    "                    sc = ax.scatter(\n",
    "                        d[exposure_col],\n",
    "                        d[rate_col],\n",
    "                        c=d[crash_col].fillna(0),\n",
    "                        alpha=0.6,\n",
    "                        s=30,\n",
    "                        vmin=vmin,\n",
    "                        vmax=vmax,\n",
    "                    )\n",
    "                else:\n",
    "                    sc = ax.scatter(\n",
    "                        d[exposure_col],\n",
    "                        d[rate_col],\n",
    "                        alpha=0.6,\n",
    "                        s=30,\n",
    "                    )\n",
    "\n",
    "                _mark_hotspots(ax, d)\n",
    "                _style_axes(ax, f\"{y}-{m:02d} (mode={MODE_ENV})\")\n",
    "\n",
    "                if scatter_for_cbar is None and crash_col is not None:\n",
    "                    scatter_for_cbar = sc\n",
    "\n",
    "            # Turn off unused axes on last page\n",
    "            for j in range(len(page_pairs), NROWS * NCOLS):\n",
    "                r, c = divmod(j, NCOLS)\n",
    "                axesA[r][c].axis(\"off\")\n",
    "\n",
    "            figA.suptitle(\n",
    "                f\"Risk vs Exposure — mode={MODE_ENV} (page {page_idx+1}/{pages})\",\n",
    "                fontsize=13, fontweight=\"bold\"\n",
    "            )\n",
    "            figA.tight_layout(rect=[0.0, 0.0, 1.0, 0.93])\n",
    "\n",
    "            # Shared colorbar that matches the axes block height (NOT the full figure)\n",
    "            if scatter_for_cbar is not None:\n",
    "                import matplotlib as mpl\n",
    "                sm = mpl.cm.ScalarMappable(norm=scatter_for_cbar.norm, cmap=scatter_for_cbar.cmap)\n",
    "                sm.set_array([])\n",
    "                visible_axes = [ax for ax in axesA.ravel() if ax.get_visible() and ax.has_data()]\n",
    "                cbar = figA.colorbar(sm, ax=visible_axes, fraction=0.035, pad=0.02)\n",
    "                cbar.set_label(\"Crash Count\")\n",
    "\n",
    "            savefig(f\"risk_vs_exposure_panel_periods_mode{MODE_ENV}_page{page_idx+1:02d}.png\")\n",
    "            plt.show()\n",
    "\n",
    "        # =========================================================\n",
    "        # PANEL B: YEARLY COMPARISON (overlay years) — one subplot per month\n",
    "        # =========================================================\n",
    "        # This scales well: one subplot per month, overlay each year.\n",
    "        n = len(months_to_plot)\n",
    "        ncols = min(3, n) if n > 1 else 1\n",
    "        nrows = int(math.ceil(n / ncols))\n",
    "\n",
    "        figB, axesB = plt.subplots(\n",
    "            nrows, ncols,\n",
    "            figsize=(4.6 * ncols, 3.6 * nrows),\n",
    "            squeeze=False\n",
    "        )\n",
    "\n",
    "        # If too many years, auto-switch to endpoints to keep readable\n",
    "        if len(years_to_plot) > 3:\n",
    "            years_overlay = [min(years_to_plot), max(years_to_plot)]\n",
    "            overlay_tag = f\"endpoints_{years_overlay[0]}_{years_overlay[1]}\"\n",
    "        else:\n",
    "            years_overlay = list(years_to_plot)\n",
    "            overlay_tag = \"allYears\"\n",
    "\n",
    "        for i, m in enumerate(months_to_plot):\n",
    "            r, c = divmod(i, ncols)\n",
    "            ax = axesB[r][c]\n",
    "\n",
    "            any_data = False\n",
    "            for y in years_overlay:\n",
    "                d = plot_df[(plot_df[\"year\"] == y) & (plot_df[\"month\"] == m)].copy()\n",
    "                if d.empty:\n",
    "                    continue\n",
    "                any_data = True\n",
    "                ax.scatter(\n",
    "                    d[exposure_col],\n",
    "                    d[rate_col],\n",
    "                    alpha=0.5,\n",
    "                    s=22,\n",
    "                    label=str(y)\n",
    "                )\n",
    "                _mark_hotspots(ax, d)\n",
    "\n",
    "            _style_axes(ax, f\"Year comparison — month {m:02d} (mode={MODE_ENV})\")\n",
    "            if any_data:\n",
    "                ax.legend(title=\"Year\", fontsize=8, title_fontsize=9, loc=\"best\")\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, \"No data\", transform=ax.transAxes, ha=\"center\", va=\"center\")\n",
    "                ax.set_axis_off()\n",
    "\n",
    "        # Turn off unused axes\n",
    "        for j in range(n, nrows * ncols):\n",
    "            r, c = divmod(j, ncols)\n",
    "            axesB[r][c].axis(\"off\")\n",
    "\n",
    "        figB.suptitle(\n",
    "            f\"Yearly comparison (overlay: {overlay_tag}) — mode={MODE_ENV}\",\n",
    "            fontsize=13, fontweight=\"bold\"\n",
    "        )\n",
    "        figB.tight_layout(rect=[0.0, 0.0, 1.0, 0.93])\n",
    "\n",
    "        savefig(f\"risk_vs_exposure_panel_year_compare_mode{MODE_ENV}_{overlay_tag}.png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd882830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: parse env selections\n",
    "# -----------------------------\n",
    "def _parse_int_list_env(name: str):\n",
    "    raw = os.environ.get(name, \"\").strip()\n",
    "    if not raw:\n",
    "        return None\n",
    "    parts = re.split(r\"[,\\s]+\", raw)\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "        try:\n",
    "            out.append(int(p))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return out or None\n",
    "\n",
    "MODE_ENV = (os.environ.get(\"CITIBIKE_MODE\", \"\") or \"unknown\").strip().lower()\n",
    "years_env = _parse_int_list_env(\"CITIBIKE_YEARS\")\n",
    "months_env = _parse_int_list_env(\"CITIBIKE_MONTHS\")\n",
    "\n",
    "# ========================================================================\n",
    "# CHECK: Does df_score have usable data for seasonality analysis?\n",
    "# ========================================================================\n",
    "needed = [\"year\", \"month\"]\n",
    "missing = [c for c in needed if c not in df_score.columns]\n",
    "\n",
    "# Also check if we have credible rows with risk data\n",
    "has_credible_data = False\n",
    "if not missing:\n",
    "    temp_df = df_score.copy()\n",
    "    if \"credibility_flag\" in temp_df.columns:\n",
    "        temp_df = temp_df[temp_df[\"credibility_flag\"] == \"credible\"]\n",
    "    has_credible_data = len(temp_df) > 0\n",
    "\n",
    "if missing or not has_credible_data:\n",
    "    print(\"=\"*80)\n",
    "    print(\"  SEASONALITY ANALYSIS SKIPPED\")\n",
    "    print(\"=\"*80)\n",
    "    if missing:\n",
    "        print(f\"Reason: df_score missing required columns: {missing}\")\n",
    "    else:\n",
    "        print(f\"Reason: No credible rows (min_trips threshold not met by any station-period)\")\n",
    "    print(f\"Mode: {MODE_ENV}\")\n",
    "    print(\"\")\n",
    "    print(\"This is expected for JC mode (smaller system, fewer high-volume stations).\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "else:\n",
    "    # ========================================================================\n",
    "    # PROCEED WITH SEASONALITY ANALYSIS\n",
    "    # ========================================================================\n",
    "    print(f\"✓ df_score has year/month columns + credible data → proceeding with seasonality analysis\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # What to plot (time-comparable)\n",
    "    # -----------------------------\n",
    "    value_col = \"eb_risk_rate_per_100k_trips\"\n",
    "    if value_col not in df_score.columns:\n",
    "        if \"risk_rate_per_100k_trips\" in df_score.columns:\n",
    "            value_col = \"risk_rate_per_100k_trips\"\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Need eb_risk_rate_per_100k_trips (or risk_rate_per_100k_trips) in df_score.\"\n",
    "            )\n",
    "\n",
    "    df = df_score.copy()\n",
    "\n",
    "    # Optional: credible only\n",
    "    if \"credibility_flag\" in df.columns:\n",
    "        df = df[df[\"credibility_flag\"] == \"credible\"].copy()\n",
    "\n",
    "    # Clean\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "    df[\"month\"] = pd.to_numeric(df[\"month\"], errors=\"coerce\")\n",
    "    df[value_col] = pd.to_numeric(df[value_col], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"year\", \"month\", value_col]).copy()\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    df[\"month\"] = df[\"month\"].astype(int)\n",
    "\n",
    "    # Apply env filters (no hardcoding)\n",
    "    years_available = sorted(df[\"year\"].unique())\n",
    "    months_available = sorted(df[\"month\"].unique())\n",
    "\n",
    "    years_to_use = years_env if years_env is not None else years_available\n",
    "    months_to_use = months_env if months_env is not None else months_available\n",
    "\n",
    "    years_to_use = [y for y in years_to_use if y in years_available]\n",
    "    months_to_use = [m for m in months_to_use if m in months_available]\n",
    "\n",
    "    df = df[df[\"year\"].isin(years_to_use) & df[\"month\"].isin(months_to_use)].copy()\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"No rows after filtering. years={years_to_use} months={months_to_use} mode={MODE_ENV}\")\n",
    "    else:\n",
    "        print(f\"[seasonality] mode={MODE_ENV} years={years_to_use} months={months_to_use} rows={len(df):,} value={value_col}\")\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # Summary stats per (year, month): median + IQR\n",
    "        # -------------------------------------------------------------------\n",
    "        g = df.groupby([\"year\", \"month\"])[value_col]\n",
    "        summary = g.quantile([0.25, 0.5, 0.75]).unstack(level=-1).reset_index()\n",
    "        summary.columns = [\"year\", \"month\", \"q25\", \"q50\", \"q75\"]\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # Plot 1: Seasonal lines (median ± IQR) per year\n",
    "        # -------------------------------------------------------------------\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 5.5))\n",
    "\n",
    "        for y in years_to_use:\n",
    "            s = summary[summary[\"year\"] == y].sort_values(\"month\")\n",
    "            if s.empty:\n",
    "                continue\n",
    "            ax1.plot(s[\"month\"], s[\"q50\"], marker=\"o\", linewidth=2, label=str(y))\n",
    "            ax1.fill_between(s[\"month\"], s[\"q25\"], s[\"q75\"], alpha=0.15)\n",
    "\n",
    "        ax1.set_title(f\"Seasonality of station risk by month (median ± IQR) — mode={MODE_ENV}\", fontweight=\"bold\")\n",
    "        ax1.set_xlabel(\"Month\")\n",
    "        ax1.set_ylabel(f\"{value_col}\")\n",
    "        ax1.set_xticks(sorted(months_to_use))\n",
    "        ax1.grid(alpha=0.3)\n",
    "        ax1.legend(\n",
    "            title=\"Year\",\n",
    "            ncol=min(6, max(1, len(years_to_use))),\n",
    "            fontsize=9,\n",
    "            title_fontsize=10\n",
    "        )\n",
    "\n",
    "        savefig(f\"seasonality_lines_median_IQR_mode{MODE_ENV}.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # -------------------------------------------------------------------\n",
    "        # Plot 2: Heatmap (Year × Month) of median risk with readable labels\n",
    "        # -------------------------------------------------------------------\n",
    "        pivot = (\n",
    "            summary.pivot(index=\"year\", columns=\"month\", values=\"q50\")\n",
    "            .reindex(index=years_to_use, columns=sorted(months_to_use))\n",
    "        )\n",
    "\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 3.0 + 0.5 * len(years_to_use)))\n",
    "\n",
    "        im = ax2.imshow(pivot.values, aspect=\"auto\", cmap=\"cividis\")\n",
    "\n",
    "        ax2.set_title(f\"Year × Month median station risk — mode={MODE_ENV}\", fontweight=\"bold\")\n",
    "        ax2.set_xlabel(\"Month\")\n",
    "        ax2.set_ylabel(\"Year\")\n",
    "\n",
    "        ax2.set_xticks(range(len(pivot.columns)))\n",
    "        ax2.set_xticklabels([f\"{m:02d}\" for m in pivot.columns])\n",
    "        ax2.set_yticks(range(len(pivot.index)))\n",
    "        ax2.set_yticklabels([str(y) for y in pivot.index])\n",
    "\n",
    "        cbar = fig2.colorbar(im, ax=ax2, fraction=0.03, pad=0.02)\n",
    "        cbar.set_label(f\"Median {value_col}\")\n",
    "\n",
    "        norm = im.norm\n",
    "        cmap = im.cmap\n",
    "        for i, y in enumerate(pivot.index):\n",
    "            for j, m in enumerate(pivot.columns):\n",
    "                val = pivot.loc[y, m]\n",
    "                if pd.isna(val):\n",
    "                    continue\n",
    "\n",
    "                rgba = cmap(norm(val))\n",
    "                luminance = 0.299 * rgba[0] + 0.587 * rgba[1] + 0.114 * rgba[2]\n",
    "                txt_color = \"black\" if luminance > 0.6 else \"white\"\n",
    "\n",
    "                ax2.text(\n",
    "                    j, i, f\"{val:.0f}\",\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    fontsize=9, fontweight=\"bold\",\n",
    "                    color=txt_color,\n",
    "                    bbox=dict(\n",
    "                        boxstyle=\"round,pad=0.15\",\n",
    "                        facecolor=(\"white\" if txt_color == \"black\" else \"black\"),\n",
    "                        alpha=0.20,\n",
    "                        edgecolor=\"none\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        fig2.tight_layout()\n",
    "        savefig(f\"seasonality_heatmap_year_month_mode{MODE_ENV}.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a795096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "def _parse_int_list_env(name: str):\n",
    "    raw = os.environ.get(name, \"\").strip()\n",
    "    if not raw:\n",
    "        return None\n",
    "    parts = re.split(r\"[,\\s]+\", raw)\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "        try:\n",
    "            out.append(int(p))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return out or None\n",
    "\n",
    "MODE_ENV = (os.environ.get(\"CITIBIKE_MODE\", \"\") or \"unknown\").strip().lower()\n",
    "years_env = _parse_int_list_env(\"CITIBIKE_YEARS\")\n",
    "months_env = _parse_int_list_env(\"CITIBIKE_MONTHS\")\n",
    "\n",
    "rate_col = \"eb_risk_rate_per_100k_trips\"\n",
    "exp_col = \"exposure_trips\"\n",
    "id_col = \"start_station_id\" if \"start_station_id\" in df_score.columns else None\n",
    "\n",
    "needed = [rate_col, exp_col]\n",
    "missing = [c for c in needed if c not in df_score.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"df_score missing required columns: {missing}\")\n",
    "\n",
    "df = df_score.copy()\n",
    "\n",
    "# Optional: credible only (keeps distributions stable)\n",
    "if \"credibility_flag\" in df.columns:\n",
    "    df = df[df[\"credibility_flag\"] == \"credible\"].copy()\n",
    "\n",
    "# Clean\n",
    "df[rate_col] = pd.to_numeric(df[rate_col], errors=\"coerce\")\n",
    "df[exp_col] = pd.to_numeric(df[exp_col], errors=\"coerce\")\n",
    "df = df.dropna(subset=[rate_col, exp_col])\n",
    "df = df[df[exp_col] > 0].copy()\n",
    "\n",
    "has_period_cols = (\"year\" in df.columns) and (\"month\" in df.columns)\n",
    "\n",
    "if not has_period_cols:\n",
    "    print(f\"[yearly-plots] No year/month columns for MODE={MODE_ENV}. Skipping yearly comparison plots.\")\n",
    "else:\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "    df[\"month\"] = pd.to_numeric(df[\"month\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"year\", \"month\"]).copy()\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    df[\"month\"] = df[\"month\"].astype(int)\n",
    "\n",
    "    years_available = sorted(df[\"year\"].unique())\n",
    "    months_available = sorted(df[\"month\"].unique())\n",
    "\n",
    "    years_to_use = years_env if years_env is not None else years_available\n",
    "    months_to_use = months_env if months_env is not None else months_available\n",
    "    years_to_use = [y for y in years_to_use if y in years_available]\n",
    "    months_to_use = [m for m in months_to_use if m in months_available]\n",
    "\n",
    "    # Filter to chosen months/years\n",
    "    df = df[df[\"year\"].isin(years_to_use) & df[\"month\"].isin(months_to_use)].copy()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"[yearly-plots] Empty after filtering. years={years_to_use} months={months_to_use} MODE={MODE_ENV}\")\n",
    "    else:\n",
    "        print(f\"[yearly-plots] MODE={MODE_ENV} years={years_to_use} months={months_to_use} rows={len(df):,}\")\n",
    "\n",
    "        # =========================================================\n",
    "        # Plot A: Distribution by year (boxplot of station-period EB rates)\n",
    "        # =========================================================\n",
    "        figA, axA = plt.subplots(figsize=(8.5, 4.8))\n",
    "\n",
    "        data_by_year = [df.loc[df[\"year\"] == y, rate_col].values for y in years_to_use]\n",
    "\n",
    "        # Use tick_labels (new matplotlib) + style median line explicitly\n",
    "        bp = axA.boxplot(\n",
    "            data_by_year,\n",
    "            tick_labels=[str(y) for y in years_to_use],\n",
    "            showfliers=False,\n",
    "            medianprops=dict(color=\"red\", linewidth=2),\n",
    "        )\n",
    "\n",
    "        axA.set_title(f\"Distribution of EB Risk Rate by Year — mode={MODE_ENV}\", fontweight=\"bold\")\n",
    "        axA.set_xlabel(\"Year\")\n",
    "        axA.set_ylabel(\"EB Risk Rate (per 100k trips)\")\n",
    "        axA.grid(alpha=0.3)\n",
    "\n",
    "        # Legend entry to explain the horizontal line is the median\n",
    "        median_handle = mlines.Line2D([], [], color=\"red\", linewidth=2, label=\"Median\")\n",
    "        axA.legend(handles=[median_handle], loc=\"best\")\n",
    "\n",
    "        # # Optional: also add a small in-plot annotation (comment out if you prefer legend only)\n",
    "        # axA.text(\n",
    "        #     0.98, 0.98,\n",
    "        #     \"Red line = median\",\n",
    "        #     transform=axA.transAxes,\n",
    "        #     ha=\"right\", va=\"top\",\n",
    "        #     fontsize=10,\n",
    "        #     bbox=dict(boxstyle=\"round,pad=0.25\", facecolor=\"white\", alpha=0.85, edgecolor=\"gray\")\n",
    "        # )\n",
    "\n",
    "        savefig(f\"yearly_distribution_boxplot_mode{MODE_ENV}.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # # =========================================================\n",
    "        # # Plot B: Station-level change (endpoints slopegraph)\n",
    "        # # =========================================================\n",
    "        # if id_col is None:\n",
    "        #     print(\"[yearly-plots] No start_station_id column; skipping station-level change plot.\")\n",
    "        # else:\n",
    "        #     # Aggregate within each year across selected months:\n",
    "        #     # exposure-weighted average EB rate (stable)\n",
    "        #     def _agg_one(grp: pd.DataFrame) -> pd.Series:\n",
    "        #         w = grp[exp_col].to_numpy()\n",
    "        #         x = grp[rate_col].to_numpy()\n",
    "        #         wsum = float(np.sum(w))\n",
    "        #         if wsum <= 0 or len(x) == 0:\n",
    "        #             return pd.Series({\"exposure_sum\": 0.0, \"eb_rate_weighted\": np.nan})\n",
    "        #         return pd.Series({\"exposure_sum\": wsum, \"eb_rate_weighted\": float(np.average(x, weights=w))})\n",
    "\n",
    "        #     g = (\n",
    "        #         df.groupby([id_col, \"year\"], as_index=False)\n",
    "        #           .apply(_agg_one)\n",
    "        #           .reset_index(drop=True)\n",
    "        #     )\n",
    "\n",
    "        #     y0, y1 = min(years_to_use), max(years_to_use)\n",
    "\n",
    "        #     gg0 = g[g[\"year\"] == y0][[id_col, \"exposure_sum\", \"eb_rate_weighted\"]].rename(\n",
    "        #         columns={\"exposure_sum\": \"exp0\", \"eb_rate_weighted\": \"rate0\"}\n",
    "        #     )\n",
    "        #     gg1 = g[g[\"year\"] == y1][[id_col, \"exposure_sum\", \"eb_rate_weighted\"]].rename(\n",
    "        #         columns={\"exposure_sum\": \"exp1\", \"eb_rate_weighted\": \"rate1\"}\n",
    "        #     )\n",
    "        #     merged = gg0.merge(gg1, on=id_col, how=\"inner\").dropna(subset=[\"rate0\", \"rate1\"]).copy()\n",
    "\n",
    "        #     if merged.empty:\n",
    "        #         print(f\"[yearly-plots] No stations present in BOTH {y0} and {y1}; skipping slopegraph.\")\n",
    "        #     else:\n",
    "        #         merged[\"exp_total\"] = merged[\"exp0\"] + merged[\"exp1\"]\n",
    "        #         TOP_N = 120\n",
    "        #         merged = merged.sort_values(\"exp_total\", ascending=False).head(TOP_N).copy()\n",
    "\n",
    "        #         figB, axB = plt.subplots(figsize=(8.5, 5.5))\n",
    "\n",
    "        #         x_positions = [0, 1]\n",
    "        #         for _, r in merged.iterrows():\n",
    "        #             axB.plot(\n",
    "        #                 x_positions,\n",
    "        #                 [r[\"rate0\"], r[\"rate1\"]],\n",
    "        #                 alpha=0.25,\n",
    "        #                 linewidth=1\n",
    "        #             )\n",
    "\n",
    "        #         # Median line for context\n",
    "        #         axB.plot(\n",
    "        #             x_positions,\n",
    "        #             [merged[\"rate0\"].median(), merged[\"rate1\"].median()],\n",
    "        #             linewidth=3,\n",
    "        #             label=\"Median (top exposure)\"\n",
    "        #         )\n",
    "\n",
    "        #         axB.set_xticks(x_positions)\n",
    "        #         axB.set_xticklabels([str(y0), str(y1)])\n",
    "        #         axB.set_title(\n",
    "        #             f\"Station-level EB Risk Change (Exposure-weighted) — months={months_to_use} — mode={MODE_ENV}\",\n",
    "        #             fontweight=\"bold\"\n",
    "        #         )\n",
    "        #         axB.set_ylabel(\"EB Risk Rate (per 100k trips)\")\n",
    "        #         axB.grid(alpha=0.3)\n",
    "        #         axB.legend()\n",
    "\n",
    "        #         savefig(f\"station_change_slopegraph_{y0}_to_{y1}_mode{MODE_ENV}.png\")\n",
    "        #         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea8edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b8abc4e",
   "metadata": {},
   "source": [
    "### Executive Risk Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- EXECUTIVE RISK SUMMARY ---\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_score\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXECUTIVE RISK SUMMARY FOR AXA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_score' is not defined"
     ]
    }
   ],
   "source": [
    "# --- EXECUTIVE RISK SUMMARY (nbconvert-safe, self-contained) ---\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MIN_TRIPS = 5000\n",
    "\n",
    "# Make sure df_score exists (avoid NameError)\n",
    "if \"df_score\" not in globals() or df_score is None or len(df_score) == 0:\n",
    "    print(\"  df_score is missing/empty — cannot build executive summary.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXECUTIVE RISK SUMMARY FOR AXA\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    s = df_score.copy()\n",
    "\n",
    "    # Defensive: ensure credibility_flag exists\n",
    "    if \"credibility_flag\" not in s.columns:\n",
    "        if \"exposure_trips\" in s.columns:\n",
    "            s[\"credibility_flag\"] = np.where(s[\"exposure_trips\"] >= MIN_TRIPS, \"credible\", \"insufficient_data\")\n",
    "        elif \"trips\" in s.columns:\n",
    "            s[\"credibility_flag\"] = np.where(s[\"trips\"] >= MIN_TRIPS, \"credible\", \"insufficient_data\")\n",
    "        else:\n",
    "            s[\"credibility_flag\"] = \"unknown\"\n",
    "\n",
    "    # Decide exposure column\n",
    "    exposure_col = \"exposure_trips\" if \"exposure_trips\" in s.columns else (\"trips\" if \"trips\" in s.columns else None)\n",
    "    if exposure_col is not None:\n",
    "        s[exposure_col] = pd.to_numeric(s[exposure_col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Infer mode label safely\n",
    "    mode_label = \"unknown\"\n",
    "    if \"mode\" in s.columns and s[\"mode\"].notna().any():\n",
    "        uniq_modes = sorted(s[\"mode\"].astype(str).unique().tolist())\n",
    "        mode_label = uniq_modes[0] if len(uniq_modes) == 1 else \"multiple\"\n",
    "\n",
    "    # Build credible_stations HERE (fixes your NameError)\n",
    "    credible_stations = s[s[\"credibility_flag\"].astype(str).str.lower() == \"credible\"].copy()\n",
    "\n",
    "    total_rows = len(s)\n",
    "    credible_count = len(credible_stations)\n",
    "\n",
    "    summary_data = []\n",
    "\n",
    "    summary_data.append({\n",
    "        \"Metric\": \"Total station-period rows\",\n",
    "        \"Value\": f\"{total_rows:,}\",\n",
    "        \"Notes\": f\"mode={mode_label}\"\n",
    "    })\n",
    "\n",
    "    if total_rows > 0:\n",
    "        pct_cred = 100.0 * credible_count / total_rows\n",
    "        summary_data.append({\n",
    "            \"Metric\": f\"Credible rows (≥{MIN_TRIPS:,} trips)\",\n",
    "            \"Value\": f\"{credible_count:,} ({pct_cred:.1f}%)\",\n",
    "            \"Notes\": \"Enough volume to trust risk ranking\"\n",
    "        })\n",
    "\n",
    "    # Optional: risk_tier counts (only if column exists)\n",
    "    if \"risk_tier\" in credible_stations.columns:\n",
    "        for tier, note in [\n",
    "            (\"High Risk\", \"Premium pricing / targeted prevention\"),\n",
    "            (\"Medium Risk\", \"Standard pricing\"),\n",
    "            (\"Low Risk\", \"Discount / acquisition-friendly\"),\n",
    "        ]:\n",
    "            n = int((credible_stations[\"risk_tier\"].astype(str) == tier).sum())\n",
    "            pct = (100.0 * n / credible_count) if credible_count > 0 else 0.0\n",
    "            summary_data.append({\n",
    "                \"Metric\": f\"{tier} rows\",\n",
    "                \"Value\": f\"{n:,} ({pct:.1f}%)\",\n",
    "                \"Notes\": note\n",
    "            })\n",
    "\n",
    "    # Hotspots (only if columns exist) — and handle True/False safely\n",
    "    def _safe_true_count(df: pd.DataFrame, col: str) -> int:\n",
    "        if col not in df.columns:\n",
    "            return 0\n",
    "        v = df[col]\n",
    "        if v.dtype == bool:\n",
    "            return int(v.sum())\n",
    "        # tolerate strings like \"True\"/\"False\"\n",
    "        return int(v.astype(str).str.lower().isin([\"true\", \"1\", \"yes\"]).sum())\n",
    "\n",
    "    for col, label, note in [\n",
    "        (\"prevention_hotspot\", \"Prevention hotspots\", \"High exposure + high risk → safety pilots\"),\n",
    "        (\"product_hotspot\", \"Product hotspots\", \"High exposure → strong sales reach\"),\n",
    "        (\"acquisition_hotspot\", \"Acquisition hotspots\", \"High exposure + low risk → easy wins\"),\n",
    "    ]:\n",
    "        if col in s.columns:\n",
    "            n = _safe_true_count(s, col)\n",
    "            summary_data.append({\n",
    "                \"Metric\": label,\n",
    "                \"Value\": f\"{n:,}\",\n",
    "                \"Notes\": note\n",
    "            })\n",
    "\n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    display(df_summary)\n",
    "\n",
    "    # Save summary (RUN_DIR safe)\n",
    "    out_dir = None\n",
    "    if \"RUN_DIR\" in globals() and RUN_DIR is not None:\n",
    "        out_dir = Path(RUN_DIR)\n",
    "    else:\n",
    "        out_dir = Path(\".\").resolve()\n",
    "\n",
    "    out_path = out_dir / \"risk_executive_summary.csv\"\n",
    "    df_summary.to_csv(out_path, index=False)\n",
    "    print(f\"\\nSaved executive summary to: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "modified_at": "2026-01-03T11:12:10.237164Z",
  "modified_by": "chatgpt"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
